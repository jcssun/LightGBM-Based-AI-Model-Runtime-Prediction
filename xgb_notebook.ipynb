{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Machine Learning Model for Performance Prediction\n",
    "\n",
    "## Introduction\n",
    "This project focuses on developing a machine learning model to predict the performance of configurations based on various features extracted from data files. We use LightGBM's ranking model to assess the impact of configurations on performance.\n",
    "\n",
    "## Data Preparation\n",
    "The data used in this project resides in the `./data/tpugraphs/npz/tile/xla` directory. Each data file contains multiple features which are pre-processed and sampled for training the model.\n",
    "\n",
    "## Model Training\n",
    "* We employ a `LightGBM Ranker` to train our model. The ranker uses features such as node characteristics and configuration parameters to predict the performance ranks within different groups.\n",
    "* The model's predictions are evaluated against a baseline to check the effectiveness of different configurations. The performance is measured by how well the model can predict the best configurations.\n",
    "\n",
    "## Directory Structure\n",
    "- `data/`: Contains the datasets in `.npz` format.\n",
    "- `scripts/`: Contains the source code.\n",
    "\n",
    "## Output\n",
    "The predictions are saved in `result_xla.csv`, which contains the configurations predicted to perform best.\n"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "\n",
    "from lightgbm import LGBMRanker\n",
    "\n",
    "from lightgbm import LGBMRegressor"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-26T03:40:30.628536Z",
     "end_time": "2024-02-26T03:40:30.637868Z"
    }
   },
   "outputs": [],
   "source": [
    "tile_path = './data/tpugraphs/npz/tile/xla'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-26T03:40:31.596451Z",
     "end_time": "2024-02-26T03:40:31.608846Z"
    }
   },
   "outputs": [],
   "source": [
    "# Function to load and process data from files\n",
    "def get_df(mode, sample_config=None):\n",
    "    file_list = os.listdir(os.path.join(tile_path, mode))  # List files in the directory\n",
    "    dlist = []\n",
    "    select_file_list = pd.Series(file_list).sample(frac=1, random_state=42)  # Shuffle file list\n",
    "    select_file_list = list(select_file_list)  # Convert to list\n",
    "\n",
    "    for fid, f in tqdm(enumerate(select_file_list)):  # Iterate through files\n",
    "        d = dict(np.load(os.path.join(tile_path, mode, f)))  # Load each file as a dictionary\n",
    "        # Validate file contents\n",
    "        assert (list(d.keys())) == ['node_feat', 'node_opcode', 'edge_index', 'config_feat', 'config_runtime', 'config_runtime_normalizers']\n",
    "\n",
    "        # Extract feature dimensions\n",
    "        node_feat_r = d['node_feat'].shape[0]\n",
    "        edge_index_r = d['edge_index'].shape[0]\n",
    "\n",
    "        cfg_num = len(d['config_feat'])\n",
    "        if sample_config:\n",
    "            sample_num = cfg_num\n",
    "            if cfg_num > 5000:\n",
    "                sample_num = 5000\n",
    "            cfg_idxs = list(pd.Series(range(cfg_num)).sample(n=sample_num, random_state=42))\n",
    "        else:\n",
    "            cfg_idxs = range(cfg_num)  # Use original order if not sampling\n",
    "\n",
    "        # Compute summary statistics for node features and configurations\n",
    "        node_mean, node_sum, node_std = np.mean(d['node_feat'], axis=0), np.sum(d['node_feat'], axis=0), np.std(d['node_feat'], axis=0)\n",
    "        config_mean, config_max, config_min, config_sum, config_std = np.mean(d['config_feat'], axis=0), np.min(d['config_feat'], axis=0), np.max(d['config_feat'], axis=0), np.sum(d['config_feat'], axis=0), np.std(d['config_feat'], axis=0)\n",
    "\n",
    "        # Append processed data to the list\n",
    "        for cfg_idx in cfg_idxs:\n",
    "            config = d['config_feat'][cfg_idx]\n",
    "            runtime = d['config_runtime'][cfg_idx]\n",
    "            runtime_n = d['config_runtime_normalizers'][cfg_idx]\n",
    "            l = [fid, f, node_feat_r, edge_index_r] + list(config) + [runtime, runtime_n]\n",
    "            dlist.append(l)\n",
    "\n",
    "    # Create a DataFrame from the list\n",
    "    cols = ['fid', 'file', 'n', 'm' ] + ['c'+str(i) for i in range(len(l)-6)] + ['runtime', 'runtime_normalizers']\n",
    "    df = pd.DataFrame(dlist, columns=cols)\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-26T03:42:48.197261Z",
     "end_time": "2024-02-26T03:44:25.799759Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "5709it [00:34, 166.71it/s]\n"
     ]
    }
   ],
   "source": [
    "train = get_df('train', sample_config=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-26T03:44:49.782432Z",
     "end_time": "2024-02-26T03:45:13.077406Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "676it [00:02, 234.69it/s]\n",
      "844it [00:04, 178.20it/s]\n",
      "676it [00:02, 236.58it/s]\n",
      "844it [00:04, 194.22it/s]\n"
     ]
    }
   ],
   "source": [
    "valid = get_df('valid', sample_config=True)\n",
    "test = get_df('test', sample_config=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "outputs": [
    {
     "data": {
      "text/plain": "   fid                                       file   n   m   c0   c1    c2  \\\n0    0  mlperf_nmt_batch_64_-2d518446041f67ae.npz  31  32  3.0  4.0  16.0   \n1    0  mlperf_nmt_batch_64_-2d518446041f67ae.npz  31  32  1.0  4.0   6.0   \n2    0  mlperf_nmt_batch_64_-2d518446041f67ae.npz  31  32  1.0  8.0   4.0   \n3    0  mlperf_nmt_batch_64_-2d518446041f67ae.npz  31  32  5.0  1.0   5.0   \n4    0  mlperf_nmt_batch_64_-2d518446041f67ae.npz  31  32  5.0  3.0   2.0   \n\n    c3   c4   c5  ...  c16  c17  c18  c19  c20  c21  c22  c23  runtime  \\\n0  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0   563141   \n1  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1787211   \n2  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1590034   \n3  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1347065   \n4  0.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1622638   \n\n   runtime_normalizers  \n0               374882  \n1               375704  \n2               375034  \n3               375378  \n4               375704  \n\n[5 rows x 30 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fid</th>\n      <th>file</th>\n      <th>n</th>\n      <th>m</th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c4</th>\n      <th>c5</th>\n      <th>...</th>\n      <th>c16</th>\n      <th>c17</th>\n      <th>c18</th>\n      <th>c19</th>\n      <th>c20</th>\n      <th>c21</th>\n      <th>c22</th>\n      <th>c23</th>\n      <th>runtime</th>\n      <th>runtime_normalizers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>mlperf_nmt_batch_64_-2d518446041f67ae.npz</td>\n      <td>31</td>\n      <td>32</td>\n      <td>3.0</td>\n      <td>4.0</td>\n      <td>16.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>563141</td>\n      <td>374882</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>mlperf_nmt_batch_64_-2d518446041f67ae.npz</td>\n      <td>31</td>\n      <td>32</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1787211</td>\n      <td>375704</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>mlperf_nmt_batch_64_-2d518446041f67ae.npz</td>\n      <td>31</td>\n      <td>32</td>\n      <td>1.0</td>\n      <td>8.0</td>\n      <td>4.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1590034</td>\n      <td>375034</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>mlperf_nmt_batch_64_-2d518446041f67ae.npz</td>\n      <td>31</td>\n      <td>32</td>\n      <td>5.0</td>\n      <td>1.0</td>\n      <td>5.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1347065</td>\n      <td>375378</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>mlperf_nmt_batch_64_-2d518446041f67ae.npz</td>\n      <td>31</td>\n      <td>32</td>\n      <td>5.0</td>\n      <td>3.0</td>\n      <td>2.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1622638</td>\n      <td>375704</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 30 columns</p>\n</div>"
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-26T03:45:13.079402Z",
     "end_time": "2024-02-26T03:45:13.129552Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "tags": [],
    "ExecuteTime": {
     "start_time": "2024-02-26T03:47:36.431790Z",
     "end_time": "2024-02-26T03:47:36.502338Z"
    }
   },
   "outputs": [],
   "source": [
    "bin_num = 10\n",
    "\n",
    "train['label'] = (train['runtime'] / train['runtime_normalizers'] * bin_num).astype(int)\n",
    "valid['label'] = (valid['runtime'] / valid['runtime_normalizers'] * bin_num).astype(int)\n",
    "\n",
    "\n",
    "# train['ori'] = train['label']\n",
    "# valid['ori'] = valid['label']\n",
    "\n",
    "# train['max'] = train.groupby('fid')['label'].apply(lambda x: x*0 + x.max())\n",
    "# valid['max'] = valid.groupby('fid')['label'].apply(lambda x: x*0 + x.max())\n",
    "\n",
    "# train['label'] = train.groupby('fid')['label'].apply(lambda x: x//(int(x.max()/bin_num)))\n",
    "# valid['label'] = valid.groupby('fid')['label'].apply(lambda x: x//(int(x.max()/bin_num)))\n",
    "\n",
    "# train['label'] = train.groupby('fid')['label'].apply(lambda x: x//(int(np.ceil(x.max()/bin_num))))\n",
    "# valid['label'] = valid.groupby('fid')['label'].apply(lambda x: x//(int(np.ceil(x.max()/bin_num))))\n",
    "\n",
    "# train['label'] = train.groupby('fid')['label'].apply(lambda x: bin_num - x//(int(np.ceil(x.max()/bin_num))))\n",
    "# valid['label'] = valid.groupby('fid')['label'].apply(lambda x: bin_num - x//(int(np.ceil(x.max()/bin_num))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [
    {
     "data": {
      "text/plain": "   fid                                               file   n   m   c0   c1  \\\n0    0  tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...  54  54  1.0  2.0   \n1    0  tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...  54  54  1.0  2.0   \n2    0  tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...  54  54  1.0  2.0   \n3    0  tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...  54  54  1.0  4.0   \n4    0  tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...  54  54  1.0  2.0   \n\n    c2   c3   c4   c5  ...  c17  c18  c19  c20  c21  c22  c23  runtime  \\\n0  8.0  1.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   267084   \n1  1.0  6.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0  1064317   \n2  2.0  6.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   385250   \n3  2.0  3.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   349327   \n4  8.0  6.0  0.0  0.0  ...  0.0  0.0  0.0  0.0  0.0  0.0  0.0   125958   \n\n   runtime_normalizers  label  \n0                56291     47  \n1                56378    188  \n2                56291     68  \n3                56358     61  \n4                56378     22  \n\n[5 rows x 31 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>fid</th>\n      <th>file</th>\n      <th>n</th>\n      <th>m</th>\n      <th>c0</th>\n      <th>c1</th>\n      <th>c2</th>\n      <th>c3</th>\n      <th>c4</th>\n      <th>c5</th>\n      <th>...</th>\n      <th>c17</th>\n      <th>c18</th>\n      <th>c19</th>\n      <th>c20</th>\n      <th>c21</th>\n      <th>c22</th>\n      <th>c23</th>\n      <th>runtime</th>\n      <th>runtime_normalizers</th>\n      <th>label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>0</td>\n      <td>tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...</td>\n      <td>54</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>1.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>267084</td>\n      <td>56291</td>\n      <td>47</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>0</td>\n      <td>tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...</td>\n      <td>54</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>1.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>1064317</td>\n      <td>56378</td>\n      <td>188</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>0</td>\n      <td>tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...</td>\n      <td>54</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>2.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>385250</td>\n      <td>56291</td>\n      <td>68</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>0</td>\n      <td>tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...</td>\n      <td>54</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>4.0</td>\n      <td>2.0</td>\n      <td>3.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>349327</td>\n      <td>56358</td>\n      <td>61</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>0</td>\n      <td>tf2_bert_pretrain_dynamic_batch_size_257ca1e9f...</td>\n      <td>54</td>\n      <td>54</td>\n      <td>1.0</td>\n      <td>2.0</td>\n      <td>8.0</td>\n      <td>6.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>...</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>0.0</td>\n      <td>125958</td>\n      <td>56378</td>\n      <td>22</td>\n    </tr>\n  </tbody>\n</table>\n<p>5 rows × 31 columns</p>\n</div>"
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "valid.head()"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "start_time": "2024-02-26T03:47:46.975262Z",
     "end_time": "2024-02-26T03:47:46.992706Z"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 0,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Define function for splitting data into bins\n",
    "def split_bin(x):\n",
    "    result_ = pd.qcut(x, q=bin_num, retbins=True, duplicates='drop')[1]\n",
    "    r = pd.cut(x, bins=result_, include_lowest=True, labels=range(len(result_)-1)).tolist()\n",
    "    r = pd.Series(r, index=x.index, ).fillna(0)\n",
    "    r = bin_num - r\n",
    "    return r"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "outputs": [],
   "source": [
    "# Apply binning to training and validation data\n",
    "train['label'] = train.groupby('fid', group_keys=False)['label'].apply(lambda x: split_bin(x))\n",
    "train['label'] = train['label'].astype(int)\n",
    "\n",
    "valid['label'] = valid.groupby('fid', group_keys=False)['label'].apply(lambda x: split_bin(x))\n",
    "valid['label'] = valid['label'].astype(int)"
   ],
   "metadata": {
    "collapsed": false
   }
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "start train\n"
     ]
    }
   ],
   "source": [
    "print('start train')\n",
    "\n",
    "label = 'label'\n",
    "feats = ['n', 'm' ] + ['c'+str(i) for i in range(24)]\n",
    "tr_x, tr_y = train[feats], train[label]\n",
    "val_x, val_y = valid[feats], valid[label]\n",
    "\n",
    "g_train = train.groupby(['fid'],)['label'].count().values\n",
    "g_val = valid.groupby(['fid'], )['label'].count().values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true,
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/local/lib/python3.8/dist-packages/lightgbm/engine.py:123: UserWarning: Found `early_stopping_rounds` in params. Will use it instead of argument\n",
      "  warnings.warn(\"Found `{}` in params. Will use it instead of argument\".format(alias))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1]\tvalid_0's ndcg@5: 0.745303\n",
      "Training until validation scores don't improve for 10 rounds.\n",
      "[2]\tvalid_0's ndcg@5: 0.77097\n",
      "[3]\tvalid_0's ndcg@5: 0.799257\n",
      "[4]\tvalid_0's ndcg@5: 0.815569\n",
      "[5]\tvalid_0's ndcg@5: 0.820369\n",
      "[6]\tvalid_0's ndcg@5: 0.83667\n",
      "[7]\tvalid_0's ndcg@5: 0.851308\n",
      "[8]\tvalid_0's ndcg@5: 0.871638\n",
      "[9]\tvalid_0's ndcg@5: 0.874978\n",
      "[10]\tvalid_0's ndcg@5: 0.877763\n",
      "[11]\tvalid_0's ndcg@5: 0.872856\n",
      "[12]\tvalid_0's ndcg@5: 0.87111\n",
      "[13]\tvalid_0's ndcg@5: 0.873603\n",
      "[14]\tvalid_0's ndcg@5: 0.871797\n",
      "[15]\tvalid_0's ndcg@5: 0.875599\n",
      "[16]\tvalid_0's ndcg@5: 0.877075\n",
      "[17]\tvalid_0's ndcg@5: 0.877016\n",
      "[18]\tvalid_0's ndcg@5: 0.878004\n",
      "[19]\tvalid_0's ndcg@5: 0.879114\n",
      "[20]\tvalid_0's ndcg@5: 0.882184\n",
      "[21]\tvalid_0's ndcg@5: 0.884394\n",
      "[22]\tvalid_0's ndcg@5: 0.885451\n",
      "[23]\tvalid_0's ndcg@5: 0.886954\n",
      "[24]\tvalid_0's ndcg@5: 0.89008\n",
      "[25]\tvalid_0's ndcg@5: 0.896522\n",
      "[26]\tvalid_0's ndcg@5: 0.895201\n",
      "[27]\tvalid_0's ndcg@5: 0.895939\n",
      "[28]\tvalid_0's ndcg@5: 0.894633\n",
      "[29]\tvalid_0's ndcg@5: 0.896722\n",
      "[30]\tvalid_0's ndcg@5: 0.897783\n",
      "[31]\tvalid_0's ndcg@5: 0.897303\n",
      "[32]\tvalid_0's ndcg@5: 0.897015\n",
      "[33]\tvalid_0's ndcg@5: 0.898041\n",
      "[34]\tvalid_0's ndcg@5: 0.899215\n",
      "[35]\tvalid_0's ndcg@5: 0.900735\n",
      "[36]\tvalid_0's ndcg@5: 0.895566\n",
      "[37]\tvalid_0's ndcg@5: 0.8964\n",
      "[38]\tvalid_0's ndcg@5: 0.896691\n",
      "[39]\tvalid_0's ndcg@5: 0.900078\n",
      "[40]\tvalid_0's ndcg@5: 0.901615\n",
      "[41]\tvalid_0's ndcg@5: 0.901638\n",
      "[42]\tvalid_0's ndcg@5: 0.902792\n",
      "[43]\tvalid_0's ndcg@5: 0.900486\n",
      "[44]\tvalid_0's ndcg@5: 0.900475\n",
      "[45]\tvalid_0's ndcg@5: 0.900733\n",
      "[46]\tvalid_0's ndcg@5: 0.902\n",
      "[47]\tvalid_0's ndcg@5: 0.901481\n",
      "[48]\tvalid_0's ndcg@5: 0.899768\n",
      "[49]\tvalid_0's ndcg@5: 0.899246\n",
      "[50]\tvalid_0's ndcg@5: 0.898792\n",
      "[51]\tvalid_0's ndcg@5: 0.899897\n"
     ]
    }
   ],
   "source": [
    "# Configure and train the model\n",
    "model = LGBMRanker(n_estimators=300, n_jobs=100, random_state=64,early_stopping_rounds=10)\n",
    "model.fit(tr_x, tr_y, \n",
    "          group=g_train, \n",
    "          eval_group=[g_val], \n",
    "          eval_set=[(val_x, val_y)],\n",
    "          eval_at=[5],\n",
    "         )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_pred = model.predict(val_x)\n",
    "valid['pred'] = - val_pred\n",
    "valid['rank'] = valid.groupby('fid')['pred'].rank(method='first')\n",
    "\n",
    "k = 5\n",
    "pred_best = valid[valid['rank']<=k].groupby('fid')['runtime'].min()\n",
    "true_best = valid.groupby('fid')['runtime'].min()\n",
    "scores = 2 - pred_best/true_best\n",
    "score = scores.mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predict and evaluate the model on validation set\n",
    "val_pred = model.predict(val_x)\n",
    "valid['pred'] = - val_pred\n",
    "valid['rank'] = valid.groupby('fid')['pred'].rank(method='first')\n",
    "\n",
    "# Calculate scores based on the top k predictions\n",
    "k = 5\n",
    "pred_best = valid[valid['rank']<=k].groupby('fid')['runtime'].min()\n",
    "true_best = valid.groupby('fid')['runtime'].min()\n",
    "scores = 2 - pred_best/true_best\n",
    "score = scores.mean()\n",
    "score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_idx(x):\n",
    "    return pd.Series(range(len(x)), index=x.index)\n",
    "\n",
    "# Use the model to predict on test set and format the output\n",
    "test['config_id'] = test.groupby('fid',group_keys=False)['file'].apply(get_idx)\n",
    "test_x = test[feats]\n",
    "test_pred = model.predict(test_x)\n",
    "test['pred'] = - test_pred\n",
    "test['rank'] = test.groupby('fid',group_keys=False)['pred'].rank(method='first')\n",
    "test_top = test[test['rank']<=5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_top = test_top.groupby('file', as_index=False)['config_id'].apply(lambda x: ';'.join(list(x.astype(str))))\n",
    "test_top['ID'] = 'tile:xla:' + test_top['file'].apply(lambda x: x.split('.')[0])\n",
    "test_top['TopConfigs'] = test_top['config_id']\n",
    "test_tile_df = test_top[['ID', 'TopConfigs']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "test_tile_df.to_csv('result_xla.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
